# Loss Function(손실함수)
* 신경망 성능의 '나쁨'을 나타내는 지표로써, 데이터를 얼마나 잘 처리하지 못하는지를 나타냄
* 여기서 -1 곱해주면 '얼마나 좋은지'를 나타내는 지표로 변함
* 즉, 손실을 최소하는 것이 목표라고 할 수 있음(weight, bias를 찾는 것이 목표)

### 1. SSE(Sum of squares for error- 오차제곱합)
* numpy 배열로 나타냈을 때, 가장 높은 확률을 가진 항목을 추정함
* y는 신경망이 추정한 값(해당 인덱스가 정답일 확률)
* t는 정답값(정답만 1이고 나머지는 0으로 표현됨: One-hot encoding)
* k는 데이터의 차원 수
* 오차가 작을 수록 실제값과 추정 값이 비슷하다 -> 정답에 가깝다

```python
def sum_squares_error(y,t):
  return 0.5 * np.sum((y-t)**2)
```

※ 원래 SSE와 다르게 딥러닝에서는 2로 나눠줌-> 델타규칙(Delta Rule) 때문
-> 경사하강법 과정에서 발생하는 오류 최소화 위해 2로 나눠줌

### 2. CEE(Cross-Entropy Error)
* y: 신경망의 출력값, t: 정답 레이블(원핫인코딩 동일)
* **분류문제**에서 많이 사용 됨. -> Target을 1로 나머지는 0으로 만들기 때문에 적용
* Accuracy 관점에서 다른 값에 비해 높기만 하면 됨. 하지만 얘가 최적의 값인지를 고민해볼 필요가 있음
* 이진 분류 문제에서 활성화 함수는 sigmoid 함수를, 2개 이상 레이블 예측 문제에서는 softmax 함수를 씀

```python
def cross_entropy_error(y,t):
  delta = 1e-7
  return -np.sum(t*np.log(y + delta))
```
### 3 MSE(Means sauared error - 평균 제곱 오차 손실)
* 연속값을 갖는 **회귀문제**에서 널리 사용됨(주식 가격 예측 등)
* (예측값 - 정답값) 제곱을 평균으로 나눔 -> 차이가 클 수록 제곱으로 인하여 값이 커짐
* 그래서 루트를 씌운 RMSE값이 나오기도 했음(값의 왜곡을 줄여주는 효과) 
* 참고) MAE는 Mean Absolute Error로 절대값을 씌운 거라고 생각하면 됨
* MSE가 크다 -> 예측값과 실제값의 차이가 크다 -> 잘 못맞춤 -> 작을 수록 좋음

```python
def MSE(y_true, y_pred):
	return np.mean(np.square((y_true - y_pred)))
```
  

# Accuracy 대신 Loss Function을 이용하는 이유는?
* **미분** 때문에 손실함수를 지표로 설정함.
* 정확도를 지표로 삼게 되면 매개변수의 미분 값이 대부분의 장소에서 0으로 나와버린다.
* 손실함수의 경우 매개변수에 따라 연속적으로 변하지만, 정확도는 그렇지 않고 불연속적이다.
